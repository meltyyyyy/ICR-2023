{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fa181a",
   "metadata": {
    "papermill": {
     "duration": 0.005835,
     "end_time": "2023-07-21T11:18:26.788961",
     "exception": false,
     "start_time": "2023-07-21T11:18:26.783126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656758c8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:26.801553Z",
     "iopub.status.busy": "2023-07-21T11:18:26.800962Z",
     "iopub.status.idle": "2023-07-21T11:18:29.272961Z",
     "shell.execute_reply": "2023-07-21T11:18:29.271864Z"
    },
    "papermill": {
     "duration": 2.481178,
     "end_time": "2023-07-21T11:18:29.275574",
     "exception": false,
     "start_time": "2023-07-21T11:18:26.794396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedGroupKFold\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998a783",
   "metadata": {
    "papermill": {
     "duration": 0.005118,
     "end_time": "2023-07-21T11:18:29.286415",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.281297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a85dbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.298663Z",
     "iopub.status.busy": "2023-07-21T11:18:29.298252Z",
     "iopub.status.idle": "2023-07-21T11:18:29.347960Z",
     "shell.execute_reply": "2023-07-21T11:18:29.347166Z"
    },
    "papermill": {
     "duration": 0.058533,
     "end_time": "2023-07-21T11:18:29.350301",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.291768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMP_PATH = \"/kaggle/input/icr-identify-age-related-conditions\"\n",
    "train = pd.read_csv(f\"{COMP_PATH}/train.csv\")\n",
    "test = pd.read_csv(f\"{COMP_PATH}/test.csv\")\n",
    "sample_submission = pd.read_csv(f\"{COMP_PATH}/sample_submission.csv\")\n",
    "greeks = pd.read_csv(f\"{COMP_PATH}/greeks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062a8fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.363384Z",
     "iopub.status.busy": "2023-07-21T11:18:29.362835Z",
     "iopub.status.idle": "2023-07-21T11:18:29.372566Z",
     "shell.execute_reply": "2023-07-21T11:18:29.371553Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.018784,
     "end_time": "2023-07-21T11:18:29.374709",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.355925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "int_denominators = {\n",
    " 'AB': 0.004273,\n",
    " 'AF': 0.00242,\n",
    " 'AH': 0.008709,\n",
    " 'AM': 0.003097,\n",
    " 'AR': 0.005244,\n",
    " 'AX': 0.008859,\n",
    " 'AY': 0.000609,\n",
    " 'AZ': 0.006302,\n",
    " 'BC': 0.007028,\n",
    " 'BD ': 0.00799,\n",
    " 'BN': 0.3531,\n",
    " 'BP': 0.004239,\n",
    " 'BQ': 0.002605,\n",
    " 'BR': 0.006049,\n",
    " 'BZ': 0.004267,\n",
    " 'CB': 0.009191,\n",
    " 'CC': 6.12e-06,\n",
    " 'CD ': 0.007928,\n",
    " 'CF': 0.003041,\n",
    " 'CH': 0.000398,\n",
    " 'CL': 0.006365,\n",
    " 'CR': 7.5e-05,\n",
    " 'CS': 0.003487,\n",
    " 'CU': 0.005517,\n",
    " 'CW ': 9.2e-05,\n",
    " 'DA': 0.00388,\n",
    " 'DE': 0.004435,\n",
    " 'DF': 0.000351,\n",
    " 'DH': 0.002733,\n",
    " 'DI': 0.003765,\n",
    " 'DL': 0.00212,\n",
    " 'DN': 0.003412,\n",
    " 'DU': 0.0013794,\n",
    " 'DV': 0.00259,\n",
    " 'DY': 0.004492,\n",
    " 'EB': 0.007068,\n",
    " 'EE': 0.004031,\n",
    " 'EG': 0.006025,\n",
    " 'EH': 0.006084,\n",
    " 'EL': 0.000429,\n",
    " 'EP': 0.009269,\n",
    " 'EU': 0.005064,\n",
    " 'FC': 0.005712,\n",
    " 'FD ': 0.005937,\n",
    " 'FE': 0.007486,\n",
    " 'FI': 0.005513,\n",
    " 'FR': 0.00058,\n",
    " 'FS': 0.006773,\n",
    " 'GB': 0.009302,\n",
    " 'GE': 0.004417,\n",
    " 'GF': 0.004374,\n",
    " 'GH': 0.003721,\n",
    " 'GI': 0.002572\n",
    "}\n",
    "def to_int(df):\n",
    "    for k, v in int_denominators.items():\n",
    "        df[k] = np.round(df[k]/v,1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537d3886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.387321Z",
     "iopub.status.busy": "2023-07-21T11:18:29.386783Z",
     "iopub.status.idle": "2023-07-21T11:18:29.474965Z",
     "shell.execute_reply": "2023-07-21T11:18:29.474175Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.096811,
     "end_time": "2023-07-21T11:18:29.476991",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.380180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>...</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ff2bfdfe9</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1284724.5</td>\n",
       "      <td>9783.0</td>\n",
       "      <td>7231.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>790.5</td>\n",
       "      <td>...</td>\n",
       "      <td>7.298162</td>\n",
       "      <td>2997.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>16439.0</td>\n",
       "      <td>458118.5</td>\n",
       "      <td>5949.0</td>\n",
       "      <td>27152.0</td>\n",
       "      <td>0.120343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007255e47698</td>\n",
       "      <td>34.0</td>\n",
       "      <td>404448.0</td>\n",
       "      <td>9783.0</td>\n",
       "      <td>11937.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>857.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>16439.0</td>\n",
       "      <td>6397248.0</td>\n",
       "      <td>7830.0</td>\n",
       "      <td>12493.0</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013f2bd269f5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1088887.0</td>\n",
       "      <td>9783.0</td>\n",
       "      <td>10449.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.709560</td>\n",
       "      <td>1682.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>3986.0</td>\n",
       "      <td>20061.0</td>\n",
       "      <td>3126876.5</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>13683.0</td>\n",
       "      <td>0.196941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>043ac50845d5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1578368.5</td>\n",
       "      <td>13802.0</td>\n",
       "      <td>24899.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>857.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>18659.0</td>\n",
       "      <td>478798.0</td>\n",
       "      <td>10736.0</td>\n",
       "      <td>35184.0</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>044fb8a146ec</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1542582.0</td>\n",
       "      <td>9783.0</td>\n",
       "      <td>4554.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>14535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.153058</td>\n",
       "      <td>83623.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>33079.0</td>\n",
       "      <td>1948873.0</td>\n",
       "      <td>12196.0</td>\n",
       "      <td>14099.0</td>\n",
       "      <td>0.096614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id     AB         AF       AH       AM      AR     AX    AY  \\\n",
       "0  000ff2bfdfe9   49.0  1284724.5   9783.0   7231.0  1552.0   79.0  42.0   \n",
       "1  007255e47698   34.0   404448.0   9783.0  11937.0  1552.0  410.0  42.0   \n",
       "2  013f2bd269f5  110.0  1088887.0   9783.0  10449.0  1552.0  760.0  42.0   \n",
       "3  043ac50845d5   59.0  1578368.5  13802.0  24899.0  1552.0  416.0  42.0   \n",
       "4  044fb8a146ec   89.0  1542582.0   9783.0   4554.0  1552.0  445.0  90.0   \n",
       "\n",
       "       AZ       BC  ...        FL       FR     FS      GB       GE         GF  \\\n",
       "0  1557.0    790.5  ...  7.298162   2997.5   14.0  1219.0  16439.0   458118.5   \n",
       "1  2145.0    175.0  ...  0.173229    857.0   84.0   999.0  16439.0  6397248.0   \n",
       "2  2035.0    175.0  ...  7.709560   1682.0  177.0  3986.0  20061.0  3126876.5   \n",
       "3  1754.0    175.0  ...  6.122162    857.0   42.0  1992.0  18659.0   478798.0   \n",
       "4   539.0  14535.0  ...  8.153058  83623.0   18.0  1764.0  33079.0  1948873.0   \n",
       "\n",
       "        GH       GI         GL  Class  \n",
       "0   5949.0  27152.0   0.120343      1  \n",
       "1   7830.0  12493.0  21.978000      0  \n",
       "2   7531.0  13683.0   0.196941      0  \n",
       "3  10736.0  35184.0   0.155829      0  \n",
       "4  12196.0  14099.0   0.096614      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FL, GLはfloat \n",
    "train = to_int(train.copy())\n",
    "test = to_int(test.copy())\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e72154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.490525Z",
     "iopub.status.busy": "2023-07-21T11:18:29.490106Z",
     "iopub.status.idle": "2023-07-21T11:18:29.579850Z",
     "shell.execute_reply": "2023-07-21T11:18:29.578856Z"
    },
    "papermill": {
     "duration": 0.099589,
     "end_time": "2023-07-21T11:18:29.582522",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.482933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "could not convert string to float: '000ff2bfdfe9'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/nanops.py:786\u001b[0m, in \u001b[0;36mnanmedian\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 786\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39;49mastype(\u001b[39m\"\u001b[39;49m\u001b[39mf8\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    787\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    788\u001b[0m     \u001b[39m# e.g. \"could not convert string to float: 'a'\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '000ff2bfdfe9'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train\u001b[39m.\u001b[39mfillna(train\u001b[39m.\u001b[39;49mmedian(), inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m test\u001b[39m.\u001b[39mfillna(test\u001b[39m.\u001b[39mmedian(), inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:11623\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.median\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11606\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m  11607\u001b[0m     _num_doc,\n\u001b[1;32m  11608\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn the median of the values over the requested axis.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11621\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11622\u001b[0m ):\n\u001b[0;32m> 11623\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49mmedian(\u001b[39mself\u001b[39;49m, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:11212\u001b[0m, in \u001b[0;36mNDFrame.median\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmedian\u001b[39m(\n\u001b[1;32m  11206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  11207\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11210\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11211\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m> 11212\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stat_function(\n\u001b[1;32m  11213\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmedian\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanmedian, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11214\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11154\u001b[0m     nv\u001b[39m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[39m=\u001b[39mname)\n\u001b[1;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[39m\"\u001b[39m\u001b[39mskipna\u001b[39m\u001b[39m\"\u001b[39m, none_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m> 11158\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  11159\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[1;32m  11160\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py:10519\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  10515\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mT\n\u001b[1;32m  10517\u001b[0m \u001b[39m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[1;32m  10518\u001b[0m \u001b[39m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[0;32m> 10519\u001b[0m res \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mreduce(blk_func)\n\u001b[1;32m  10520\u001b[0m out \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_constructor(res)\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[1;32m  10521\u001b[0m \u001b[39mif\u001b[39;00m out_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/managers.py:1534\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1532\u001b[0m res_blocks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[1;32m   1533\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m-> 1534\u001b[0m     nbs \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mreduce(func)\n\u001b[1;32m   1535\u001b[0m     res_blocks\u001b[39m.\u001b[39mextend(nbs)\n\u001b[1;32m   1537\u001b[0m index \u001b[39m=\u001b[39m Index([\u001b[39mNone\u001b[39;00m])  \u001b[39m# placeholder\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/blocks.py:339\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce\u001b[39m(\u001b[39mself\u001b[39m, func) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[1;32m    335\u001b[0m     \u001b[39m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     \u001b[39m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m--> 339\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues)\n\u001b[1;32m    341\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    342\u001b[0m         \u001b[39m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m    343\u001b[0m         res_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[result]])\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py:10482\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  10480\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39m_reduce(name, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m  10481\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m> 10482\u001b[0m     \u001b[39mreturn\u001b[39;00m op(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    156\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/nanops.py:789\u001b[0m, in \u001b[0;36mnanmedian\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    786\u001b[0m         values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mf8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    787\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    788\u001b[0m         \u001b[39m# e.g. \"could not convert string to float: 'a'\"\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mstr\u001b[39m(err)) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m     values[mask] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n",
      "\u001b[0;31mTypeError\u001b[0m: could not convert string to float: '000ff2bfdfe9'"
     ]
    }
   ],
   "source": [
    "train.fillna(train.median(), inplace=True)\n",
    "test.fillna(test.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7c64c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.596145Z",
     "iopub.status.busy": "2023-07-21T11:18:29.595538Z",
     "iopub.status.idle": "2023-07-21T11:18:29.601189Z",
     "shell.execute_reply": "2023-07-21T11:18:29.600529Z"
    },
    "papermill": {
     "duration": 0.014755,
     "end_time": "2023-07-21T11:18:29.603245",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.588490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = train.columns\n",
    "feat_cols = cols[1:]\n",
    "num_cols = train.select_dtypes(include=['float64']).columns\n",
    "print(\"No of Columns:\", len(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6294061e",
   "metadata": {
    "papermill": {
     "duration": 0.005494,
     "end_time": "2023-07-21T11:18:29.614536",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.609042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e527f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.627972Z",
     "iopub.status.busy": "2023-07-21T11:18:29.627338Z",
     "iopub.status.idle": "2023-07-21T11:18:29.634247Z",
     "shell.execute_reply": "2023-07-21T11:18:29.633546Z"
    },
    "papermill": {
     "duration": 0.016034,
     "end_time": "2023-07-21T11:18:29.636286",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.620252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def competition_log_loss(y_true, y_pred):\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0)) / N_0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1)) / N_1\n",
    "    return (log_loss_0 + log_loss_1)/2\n",
    "\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1))\n",
    "    w_0 = 1 / N_0\n",
    "    w_1 = 1 / N_1\n",
    "    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\n",
    "    return balanced_log_loss/(N_0+N_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d23267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.649936Z",
     "iopub.status.busy": "2023-07-21T11:18:29.649263Z",
     "iopub.status.idle": "2023-07-21T11:18:29.653209Z",
     "shell.execute_reply": "2023-07-21T11:18:29.652524Z"
    },
    "papermill": {
     "duration": 0.012986,
     "end_time": "2023-07-21T11:18:29.655069",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.642083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lgb_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b8998",
   "metadata": {
    "papermill": {
     "duration": 0.005499,
     "end_time": "2023-07-21T11:18:29.666406",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.660907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356e1e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.680155Z",
     "iopub.status.busy": "2023-07-21T11:18:29.679512Z",
     "iopub.status.idle": "2023-07-21T11:18:29.689301Z",
     "shell.execute_reply": "2023-07-21T11:18:29.688535Z"
    },
    "papermill": {
     "duration": 0.019081,
     "end_time": "2023-07-21T11:18:29.691363",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.672282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "train['EJ'] = train['EJ'].map({'A': 0, 'B': 1})\n",
    "test['EJ']  = test['EJ'].map({'A': 0, 'B': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a523b0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.704614Z",
     "iopub.status.busy": "2023-07-21T11:18:29.704199Z",
     "iopub.status.idle": "2023-07-21T11:18:29.756913Z",
     "shell.execute_reply": "2023-07-21T11:18:29.756091Z"
    },
    "papermill": {
     "duration": 0.06144,
     "end_time": "2023-07-21T11:18:29.758763",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.697323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df, test_df = train.copy(), test.copy()\n",
    "new_num_cols = train.select_dtypes(include=['float64']).columns\n",
    "df[new_num_cols] = scaler.fit_transform(train[new_num_cols])\n",
    "test_df[new_num_cols] = scaler.transform(test[new_num_cols])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f72abe",
   "metadata": {
    "papermill": {
     "duration": 0.005973,
     "end_time": "2023-07-21T11:18:29.771039",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.765066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Multilabel Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc8c2a",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.786241Z",
     "iopub.status.busy": "2023-07-21T11:18:29.785500Z",
     "iopub.status.idle": "2023-07-21T11:18:29.816381Z",
     "shell.execute_reply": "2023-07-21T11:18:29.815561Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.041506,
     "end_time": "2023-07-21T11:18:29.818718",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.777212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/trent-b/iterative-stratification\n",
    "# I copied it from the above github.\n",
    "import numpy as np\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import _num_samples, check_array\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits, \\\n",
    "    BaseShuffleSplit, _validate_shuffle_split\n",
    "\n",
    "def IterativeStratification(labels, r, random_state):\n",
    "    \"\"\"This function implements the Iterative Stratification algorithm described\n",
    "    in the following paper:\n",
    "    Sechidis K., Tsoumakas G., Vlahavas I. (2011) On the Stratification of\n",
    "    Multi-Label Data. In: Gunopulos D., Hofmann T., Malerba D., Vazirgiannis M.\n",
    "    (eds) Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n",
    "    2011. Lecture Notes in Computer Science, vol 6913. Springer, Berlin,\n",
    "    Heidelberg.\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = labels.shape[0]\n",
    "    test_folds = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    # Calculate the desired number of examples at each subset\n",
    "    c_folds = r * n_samples\n",
    "\n",
    "    # Calculate the desired number of examples of each label at each subset\n",
    "    c_folds_labels = np.outer(r, labels.sum(axis=0))\n",
    "\n",
    "    labels_not_processed_mask = np.ones(n_samples, dtype=bool)\n",
    "\n",
    "    while np.any(labels_not_processed_mask):\n",
    "        # Find the label with the fewest (but at least one) remaining examples,\n",
    "        # breaking ties randomly\n",
    "        num_labels = labels[labels_not_processed_mask].sum(axis=0)\n",
    "\n",
    "        # Handle case where only all-zero labels are left by distributing\n",
    "        # across all folds as evenly as possible (not in original algorithm but\n",
    "        # mentioned in the text). (By handling this case separately, some\n",
    "        # code redundancy is introduced; however, this approach allows for\n",
    "        # decreased execution time when there are a relatively large number\n",
    "        # of all-zero labels.)\n",
    "        if num_labels.sum() == 0:\n",
    "            sample_idxs = np.where(labels_not_processed_mask)[0]\n",
    "\n",
    "            for sample_idx in sample_idxs:\n",
    "                fold_idx = np.where(c_folds == c_folds.max())[0]\n",
    "\n",
    "                if fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(fold_idx.shape[0])]\n",
    "\n",
    "                test_folds[sample_idx] = fold_idx\n",
    "                c_folds[fold_idx] -= 1\n",
    "\n",
    "            break\n",
    "\n",
    "        label_idx = np.where(num_labels == num_labels[np.nonzero(num_labels)].min())[0]\n",
    "        if label_idx.shape[0] > 1:\n",
    "            label_idx = label_idx[random_state.choice(label_idx.shape[0])]\n",
    "\n",
    "        sample_idxs = np.where(np.logical_and(labels[:, label_idx].flatten(), labels_not_processed_mask))[0]\n",
    "\n",
    "        for sample_idx in sample_idxs:\n",
    "            # Find the subset(s) with the largest number of desired examples\n",
    "            # for this label, breaking ties by considering the largest number\n",
    "            # of desired examples, breaking further ties randomly\n",
    "            label_folds = c_folds_labels[:, label_idx]\n",
    "            fold_idx = np.where(label_folds == label_folds.max())[0]\n",
    "\n",
    "            if fold_idx.shape[0] > 1:\n",
    "                temp_fold_idx = np.where(c_folds[fold_idx] ==\n",
    "                                         c_folds[fold_idx].max())[0]\n",
    "                fold_idx = fold_idx[temp_fold_idx]\n",
    "\n",
    "                if temp_fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(temp_fold_idx.shape[0])]\n",
    "\n",
    "            test_folds[sample_idx] = fold_idx\n",
    "            labels_not_processed_mask[sample_idx] = False\n",
    "\n",
    "            # Update desired number of examples\n",
    "            c_folds_labels[fold_idx, labels[sample_idx]] -= 1\n",
    "            c_folds[fold_idx] -= 1\n",
    "\n",
    "    return test_folds\n",
    "\n",
    "class MultilabelStratifiedKFold(_BaseKFold):\n",
    "    \"\"\"Multilabel stratified K-Folds cross-validator\n",
    "    Provides train/test indices to split multilabel data into train/test sets.\n",
    "    This cross-validation object is a variation of KFold that returns\n",
    "    stratified folds for multilabel data. The folds are made by preserving\n",
    "    the percentage of samples for each label.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=3\n",
    "        Number of folds. Must be at least 2.\n",
    "    shuffle : boolean, optional\n",
    "        Whether to shuffle each stratification of the data before splitting\n",
    "        into batches.\n",
    "    random_state : int, RandomState instance or None, optional, default=None\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedKFold that only uses random_state\n",
    "        when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> mskf = MultilabelStratifiedKFold(n_splits=2, random_state=0)\n",
    "    >>> mskf.get_n_splits(X, y)\n",
    "    2\n",
    "    >>> print(mskf)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    MultilabelStratifiedKFold(n_splits=2, random_state=0, shuffle=False)\n",
    "    >>> for train_index, test_index in mskf.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different in each fold.\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedMultilabelStratifiedKFold: Repeats Multilabel Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=3, *, shuffle=False, random_state=None):\n",
    "        super(MultilabelStratifiedKFold, self).__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def _make_test_folds(self, X, y):\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(type_of_target_y))\n",
    "\n",
    "        num_samples = y.shape[0]\n",
    "\n",
    "        rng = check_random_state(self.random_state)\n",
    "        indices = np.arange(num_samples)\n",
    "\n",
    "        if self.shuffle:\n",
    "            rng.shuffle(indices)\n",
    "            y = y[indices]\n",
    "\n",
    "        r = np.asarray([1 / self.n_splits] * self.n_splits)\n",
    "\n",
    "        test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "        return test_folds[np.argsort(indices)]\n",
    "\n",
    "    def _iter_test_masks(self, X=None, y=None, groups=None):\n",
    "        test_folds = self._make_test_folds(X, y)\n",
    "        for i in range(self.n_splits):\n",
    "            yield test_folds == i\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedKFold, self).split(X, y, groups)\n",
    "\n",
    "class RepeatedMultilabelStratifiedKFold(_RepeatedSplits):\n",
    "    \"\"\"Repeated Multilabel Stratified K-Fold cross validator.\n",
    "    Repeats Mulilabel Stratified K-Fold n times with different randomization\n",
    "    in each repetition.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of folds. Must be at least 2.\n",
    "    n_repeats : int, default=10\n",
    "        Number of times cross-validator needs to be repeated.\n",
    "    random_state : None, int or RandomState, default=None\n",
    "        Random state to be used to generate random state for each\n",
    "        repetition as well as randomly breaking ties within the iterative\n",
    "        stratification algorithm.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import RepeatedMultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> rmskf = RepeatedMultilabelStratifiedKFold(n_splits=2, n_repeats=2,\n",
    "    ...     random_state=0)\n",
    "    >>> for train_index, test_index in rmskf.split(X, y):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    ...\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [0 1 4 5] TEST: [2 3 6 7]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedStratifiedKFold: Repeats (Non-multilabel) Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=5, *, n_repeats=10, random_state=None):\n",
    "        super(RepeatedMultilabelStratifiedKFold, self).__init__(\n",
    "            MultilabelStratifiedKFold, n_repeats=n_repeats, random_state=random_state,\n",
    "            n_splits=n_splits)\n",
    "\n",
    "class MultilabelStratifiedShuffleSplit(BaseShuffleSplit):\n",
    "    \"\"\"Multilabel Stratified ShuffleSplit cross-validator\n",
    "    Provides train/test indices to split data into train/test sets.\n",
    "    This cross-validation object is a merge of MultilabelStratifiedKFold and\n",
    "    ShuffleSplit, which returns stratified randomized folds for multilabel\n",
    "    data. The folds are made by preserving the percentage of each label.\n",
    "    Note: like the ShuffleSplit strategy, multilabel stratified random splits\n",
    "    do not guarantee that all folds will be different, although this is\n",
    "    still very likely for sizeable datasets.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default 10\n",
    "        Number of re-shuffling & splitting iterations.\n",
    "    test_size : float, int, None, optional\n",
    "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
    "        of the dataset to include in the test split. If int, represents the\n",
    "        absolute number of test samples. If None, the value is set to the\n",
    "        complement of the train size. By default, the value is set to 0.1.\n",
    "        The default will change in version 0.21. It will remain 0.1 only\n",
    "        if ``train_size`` is unspecified, otherwise it will complement\n",
    "        the specified ``train_size``.\n",
    "    train_size : float, int, or None, default is None\n",
    "        If float, should be between 0.0 and 1.0 and represent the\n",
    "        proportion of the dataset to include in the train split. If\n",
    "        int, represents the absolute number of train samples. If None,\n",
    "        the value is automatically set to the complement of the test size.\n",
    "    random_state : int, RandomState instance or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedShuffleSplit that only uses\n",
    "        random_state when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> msss = MultilabelStratifiedShuffleSplit(n_splits=3, test_size=0.5,\n",
    "    ...    random_state=0)\n",
    "    >>> msss.get_n_splits(X, y)\n",
    "    3\n",
    "    >>> print(mss)       # doctest: +ELLIPSIS\n",
    "    MultilabelStratifiedShuffleSplit(n_splits=3, random_state=0, test_size=0.5,\n",
    "                                     train_size=None)\n",
    "    >>> for train_index, test_index in msss.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    TRAIN: [1 2 5 6] TEST: [0 3 4 7]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different from desired due to the\n",
    "    preference of stratification over perfectly sized folds.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=10, *, test_size=\"default\", train_size=None,\n",
    "                 random_state=None):\n",
    "        super(MultilabelStratifiedShuffleSplit, self).__init__(\n",
    "            n_splits=n_splits, test_size=test_size, train_size=train_size, random_state=random_state)\n",
    "\n",
    "    def _iter_indices(self, X, y, groups=None):\n",
    "        n_samples = _num_samples(X)\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(\n",
    "                    type_of_target_y))\n",
    "\n",
    "        n_train, n_test = _validate_shuffle_split(n_samples, self.test_size,\n",
    "                                                  self.train_size)\n",
    "\n",
    "        n_samples = y.shape[0]\n",
    "        rng = check_random_state(self.random_state)\n",
    "        y_orig = y.copy()\n",
    "\n",
    "        r = np.array([n_train, n_test]) / (n_train + n_test)\n",
    "\n",
    "        for _ in range(self.n_splits):\n",
    "            indices = np.arange(n_samples)\n",
    "            rng.shuffle(indices)\n",
    "            y = y_orig[indices]\n",
    "\n",
    "            test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "            test_idx = test_folds[np.argsort(indices)] == 1\n",
    "            test = np.where(test_idx)[0]\n",
    "            train = np.where(~test_idx)[0]\n",
    "\n",
    "            yield train, test\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedShuffleSplit, self).split(X, y, groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d8903",
   "metadata": {
    "papermill": {
     "duration": 0.006041,
     "end_time": "2023-07-21T11:18:29.831195",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.825154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94beea48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.845624Z",
     "iopub.status.busy": "2023-07-21T11:18:29.845208Z",
     "iopub.status.idle": "2023-07-21T11:18:29.888016Z",
     "shell.execute_reply": "2023-07-21T11:18:29.886973Z"
    },
    "papermill": {
     "duration": 0.053028,
     "end_time": "2023-07-21T11:18:29.890400",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.837372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "df['fold'] = -1\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X=train, y=greeks.iloc[:,1:3])):\n",
    "    df.loc[test_idx, 'fold'] = fold\n",
    "\n",
    "df.groupby('fold')[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8dad1b",
   "metadata": {
    "papermill": {
     "duration": 0.006149,
     "end_time": "2023-07-21T11:18:29.903091",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.896942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3ab00d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:18:29.917178Z",
     "iopub.status.busy": "2023-07-21T11:18:29.916820Z",
     "iopub.status.idle": "2023-07-21T11:18:51.783200Z",
     "shell.execute_reply": "2023-07-21T11:18:51.781654Z"
    },
    "papermill": {
     "duration": 21.87642,
     "end_time": "2023-07-21T11:18:51.785792",
     "exception": false,
     "start_time": "2023-07-21T11:18:29.909372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = balanced_log_loss\n",
    "final_valid_predictions = {}\n",
    "final_test_predictions = []\n",
    "scores = []\n",
    "log_losses = []\n",
    "balanced_log_losses = []\n",
    "weights = []\n",
    "outer_cv_score = [] # store all cv scores of outer loop inference\n",
    "inner_cv_score = [] # store all cv scores of inner loop training\n",
    "\n",
    "for fold in range(5):\n",
    "    train_df = df[df['fold'] != fold]\n",
    "    valid_df = df[df['fold'] == fold]\n",
    "    valid_ids = valid_df.Id.values.tolist()\n",
    "\n",
    "    X_train, y_train = train_df.drop(['Id', 'Class', 'fold'], axis=1), train_df['Class']\n",
    "    X_valid, y_valid = valid_df.drop(['Id', 'Class', 'fold'], axis=1), valid_df['Class']\n",
    "    \n",
    "    lgb = LGBMClassifier(boosting_type='goss', learning_rate=0.06733232950390658, n_estimators = 50000, \n",
    "                         early_stopping_round = 300, random_state=42,\n",
    "                        subsample=0.6970532011679706,\n",
    "                        colsample_bytree=0.6055755840633003,\n",
    "                         class_weight='balanced',\n",
    "                         metric='none', is_unbalance=True, max_depth=8)\n",
    "    \n",
    "    # 20% hold-out set\n",
    "    holdout = pd.concat([X_valid,y_valid], axis = 1)\n",
    "    \n",
    "    # Create an oof array for inner loop\n",
    "    oof_inner = np.zeros(len(X_train))\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    models_ = []\n",
    "    \n",
    "    print(f\"Outer Loop fold {fold}, Inner Loop Training with {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
    "    for fold, (fit_idx, val_idx) in enumerate(cv.split(X=X_train, y=y_train)):\n",
    "        X_fit = X_train.iloc[fit_idx]\n",
    "        X_val = X_train.iloc[val_idx]\n",
    "        y_fit = y_train.iloc[fit_idx]\n",
    "        y_val = y_train.iloc[val_idx]\n",
    "        \n",
    "        model = lgb.fit(X_fit, y_fit, eval_set=(X_valid, y_valid), verbose=0,\n",
    "            eval_metric=lgb_metric)\n",
    "        models_.append(model)\n",
    "        val_preds = model.predict(X_val)\n",
    "        oof_inner[val_idx] = val_preds\n",
    "        val_score = balanced_log_loss(y_val, val_preds)\n",
    "        best_iter = model.booster_.best_iteration\n",
    "        print(f'Fold: {fold:>3}| {metric.__name__}: {val_score:.5f}'\n",
    "              f' | Best iteration: {best_iter:>4}')\n",
    "        \n",
    "    mean_cv_score = metric(y_train, oof_inner)\n",
    "    print(f'80% data CV score: {metric.__name__}: {mean_cv_score:.5f}')\n",
    "    print(f'{\"*\" * 50}\\n')\n",
    "    inner_cv_score.append(mean_cv_score)\n",
    "    \n",
    "    # infer 20% data using 5-fold model trained in inner loop\n",
    "    preds = np.zeros(len(holdout))\n",
    "    for model in models_:\n",
    "        preds += model.predict(X_valid)\n",
    "    preds = preds / len(models_)\n",
    "    cv_score = metric(y_valid, preds)\n",
    "    print(f'20% data CV score: {metric.__name__}: {cv_score:.5f}')\n",
    "    print(f'{\"*\" * 50}\\n')\n",
    "    outer_cv_score.append(cv_score)\n",
    "print(f'80% data average CV score: {metric.__name__}: {np.mean(inner_cv_score):.5f}')\n",
    "print(f'{\"*\" * 50}\\n')\n",
    "\n",
    "print(f'20% data average CV score: {metric.__name__}: {np.mean(outer_cv_score):.5f}')\n",
    "print(f'{\"*\" * 50}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ab21a",
   "metadata": {
    "papermill": {
     "duration": 0.007781,
     "end_time": "2023-07-21T11:18:51.801898",
     "exception": false,
     "start_time": "2023-07-21T11:18:51.794117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.258152,
   "end_time": "2023-07-21T11:18:52.832053",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-21T11:18:15.573901",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
